{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import config\n",
    "import random\n",
    "from models import EmbeddingFaceNet\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = '../MNIST-OneShotLearning/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test images:  100\n"
     ]
    }
   ],
   "source": [
    "list_test_path = []\n",
    "for id_class, name in enumerate(config.class_name):\n",
    "    class_path = os.path.join(config.train_path, name)\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        list_test_path.append((img_path, id_class))\n",
    "print('Number of test images: ', len(list_test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img(img_path):\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = list_test_path[1]\n",
    "\n",
    "train_transforms = A.Compose([\n",
    "        A.Rotate(limit = 30, p=1),\n",
    "        A.ShiftScaleRotate(scale_limit = (-0.25, -0.1), shift_limit=0.15, rotate_limit=0, p = 1, border_mode = 1),\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.3,0.3), contrast_limit=(-0.1, 0.1), p=1),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "    ])\n",
    "def transforms(img_path):\n",
    "    img = get_img(img_path)\n",
    "    new_img = train_transforms(image = img)['image']\n",
    "    return cv2.cvtColor(new_img, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRANSFORMS = 3\n",
    "for id_class, name in enumerate(config.class_name):\n",
    "    class_path = os.path.join(config.train_path, name)\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        for i in range(NUM_TRANSFORMS):\n",
    "            img = transforms(img_path)\n",
    "            cv2.imwrite(os.path.join(class_path, 'trans_{}_{}.png'.format(img_name, i)), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
